# 02.7.1 - CI Test Flakiness: Phase 1 - Identification & Metrics

**Parent Issue**: #145 (02.7 - CI Test Flakiness - Investigation & Infrastructure)
**Phase**: 1 of 4
**Timeline**: 2 weeks
**Goal**: Understand the scope and severity of test flakiness

## Description

Mine CI logs to identify which tests are flaky, calculate failure rates, and establish baseline metrics. This phase provides data-driven insights into what needs to be fixed and prioritizes work based on impact.

## Tasks

### Week 1: Data Collection
- [ ] Extract test results from last 60 days of CI runs
  ```bash
  gh run list --workflow=ci.yml --limit 300 --json conclusion,databaseId,createdAt
  ```
- [ ] Download test result bundles for failed runs
- [ ] Parse xcresult files to extract individual test results
- [ ] Build database/spreadsheet of test runs with pass/fail outcomes

### Week 2: Analysis & Reporting
- [ ] Calculate failure rate per test (failures / total runs)
- [ ] Calculate failure rate per test suite
- [ ] Identify environmental patterns (time of day, specific CI runners, PR vs main)
- [ ] Categorize by severity:
  - Critical: >10% failure rate
  - High: 5-10% failure rate
  - Medium: 2-5% failure rate
  - Low: <2% failure rate
- [ ] Create flakiness dashboard (Markdown table)
- [ ] Write baseline report with findings

## Acceptance Criteria

- [ ] **Test Result Database**: 60 days of CI test results collected and parsed
- [ ] **Failure Rates Calculated**: Every test has documented failure rate (X failures / Y total runs)
- [ ] **Top 10 Flakiest Tests Identified**: Listed with specific failure rates
- [ ] **Baseline Metrics Established**:
  - Overall flakiness rate (% of test runs with at least one failure)
  - CI re-run frequency (% of PRs that required re-running tests)
  - Distribution across test suites
- [ ] **Flakiness Dashboard Created**: Markdown table showing per-suite and per-test metrics
- [ ] **Environmental Patterns Documented**: Any correlation with CI runner, time, PR vs main

## Deliverables

### 1. Flakiness Baseline Report
**File**: `dev-log/02.7.1-flakiness-baseline-report.md`

**Contents**:
```markdown
# Flakiness Baseline Report (2025-11-27)

## Summary Metrics
- Total CI runs analyzed: XXX
- Date range: YYYY-MM-DD to YYYY-MM-DD
- Overall flakiness rate: XX%
- Total flaky tests identified: XX

## Top 10 Flakiest Tests
| Rank | Test | Suite | Failure Rate | Failures/Runs |
|------|------|-------|--------------|---------------|
| 1 | testFoo() | SwipePersistenceTests | 15.2% | 23/151 |
| ... | ... | ... | ... | ... |

## Flakiness by Suite
| Suite | Failure Rate | Flaky Tests | Total Tests |
|-------|--------------|-------------|-------------|
| CoreUINavigationTests | 3.2% | 2 | 8 |
| ... | ... | ... | ... |

## Environmental Patterns
- Flakiness higher on weekday mornings (7am-9am UTC)?
- Specific CI runners more flaky?
- PR runs vs main branch differences?

## Recommendations
- Priority 1: Fix tests with >10% failure rate (X tests)
- Priority 2: Investigate suite-wide patterns (e.g., all persistence tests)
- Priority 3: Address environmental issues if identified
```

### 2. Flakiness Dashboard
**File**: `docs/testing/flakiness-dashboard.md`

**Contents**: Live tracking table updated weekly
```markdown
| Suite | Flakiness Rate | Flakiest Test | Last Updated |
|-------|----------------|---------------|--------------|
| CoreUINavigationTests | 3.2% | testTabBar (8%) | 2025-11-27 |
| SwipeConfigurationTests | 1.8% | testPersistence (4%) | 2025-11-27 |
```

### 3. Test Results Database
**Format**: CSV or SQLite
**Schema**:
```
run_id, test_suite, test_name, result (pass/fail), timestamp, ci_runner, branch, pr_number
```

## Tools & Scripts

### Script 1: Extract CI Test Results
**File**: `scripts/extract-ci-test-results.sh`
```bash
#!/bin/bash
# Downloads last N CI runs and extracts test results
# Usage: ./scripts/extract-ci-test-results.sh 100
```

### Script 2: Calculate Flakiness Metrics
**File**: `scripts/calculate-flakiness.py`
```python
# Reads test results database and calculates failure rates
# Outputs: flakiness dashboard + baseline report
```

## Success Metrics

**Before (Unknown)**:
- Flakiness rate: ?
- Flaky tests: ?
- Re-run frequency: ?

**After This Phase**:
- Flakiness rate: Measured and documented
- Top 10 flaky tests: Identified with specific rates
- Re-run frequency: Measured
- Baseline established for tracking improvement

## Notes

**What We're NOT Doing Yet**:
- ❌ Fixing flaky tests (that's Phase 4)
- ❌ Implementing infrastructure (that's Phase 3)
- ❌ Root cause analysis (that's Phase 2)

**What We ARE Doing**:
- ✅ Measuring the problem
- ✅ Identifying what to fix
- ✅ Establishing baseline for improvement tracking

## References

- Parent: #145 (02.7 - CI Test Flakiness Master Issue)
- GitHub Actions API: https://docs.github.com/en/rest/actions
- xcresulttool: `xcrun xcresulttool help`

# Issue 12.7: UI Test Reliability & CI Resilience

## Priority
High â€“ repeated GitHub Actions UI test timeouts are blocking merges

## Status
ðŸ”„ Planned

## Description
Stabilize the UI regression suite so GitHub Actions runs finish consistently by trimming oversized scenarios, scaling waits for hosted simulators, and capturing actionable diagnostics whenever an element lookup stalls. The goal is to keep the acceptance coverage intact while cutting the flake rate that currently prevents clean CI runs.

## Problem Statement
Recent workflows on `feature/issue-02.1.3-batch-operations-wrapup` fail in the UI phase because:
- Individual tests drive multi-minute journeys (launch â†’ library â†’ podcast â†’ multi-select) making any slow lookup exhaust the 20â€¯s CI timeout.
- Helpers do not expose tunable wait multipliers, so hosted runners with slower simulators consistently miss elements.
- Failures log generic "element not found" messages without attaching the accessibility tree, forcing manual triage.
- UI plans run monolithically, so a single timeout cancels the entire regression.

## Acceptance Criteria

### Scenario 1: Tunable Waits and Diagnostics
- [ ] Introduce a `UITEST_TIMEOUT_SCALE` (or similar) launch environment flag that scales `adaptiveTimeout` and `adaptiveShortTimeout` in `UITestHelpers`.
- [ ] Default the GitHub Actions workflow to set the scale â‰¥ 1.5 for UI jobs.
- [ ] Ensure `waitForAnyElement`, `waitForLoadingToComplete`, and related helpers attach `app.debugDescription` (or equivalent targeted dumps) when timing out on CI.

### Scenario 2: Leaner, Independent Scenarios
- [ ] Split or refactor long-running tests (e.g., `ContentDiscoveryUITests.testAcceptanceCriteria_CompleteNavigationFlow`, multi-select flows in `BatchOperationUITests`) so each case focuses on a single transition and exits early if prerequisites are missing.
- [ ] Centralize expensive app launch and navigation in reusable setup helpers to avoid relaunching for every step.
- [ ] Move feature-gating `XCTSkip` checks before deep navigation, preventing unnecessary work when a control is absent.

### Scenario 3: CI Orchestration Updates
- [ ] Update `zpod.xctestplan` (or add complementary plans) so UI suites can run in smaller shards (e.g., Navigation, Discovery, Batch Ops) on GitHub Actions.
- [ ] Adjust the GitHub Actions workflow to execute the shards sequentially or in parallel with appropriate timeouts and shared simulator warm-up.
- [ ] Record UI performance metrics or logs per shard and archive them with the existing `TestResults/` rotation rules.

### Scenario 4: Documentation & Traceability
- [ ] Add a dedicated entry to `dev-log/` summarizing the reliability strategy, environment flags, and CI updates.
- [ ] Update `zpodUITests/TestSummary.md` to reflect the new structure and highlight any remaining edge cases.
- [ ] Capture follow-up ideas (if any) as `TODO` comments with the proper `Issue #12.7` format or new sub-issues.

## Implementation Approach

1. **Helper Enhancements** â€“ Extend `UITestHelpers` with timeout scaling, centralized diagnostics, and predicate-based waits where helpful.
2. **Test Restructuring** â€“ Break apart oversized tests, factor shared launch/navigation helpers, and reposition `XCTSkip` guards.
3. **CI Plan & Workflow** â€“ Create additional test plan entries, tweak the GitHub Actions job matrix, and configure the new environment flag.
4. **Documentation & Follow-up** â€“ Update logs, summaries, and any developer guidance that references UI test execution.

## Specification References
- `zpod/spec/ui.md` â€“ UI coverage expectations for navigation, discovery, and batch operations.
- `zpod/spec/spec.md` â€“ Global testing mandates tied to Given/When/Then scenarios.
- `zpod/spec/advanced.md` â€“ Guidance on performance and diagnostics for asynchronous UI flows.

## Dependencies
- Issue 12.2 (Testing Framework Refactoring) â€“ establishes spec-driven structure referenced by UI suites.
- Issue 12.4 (Performance Testing Patterns) â€“ outlines metrics collection during automated runs.
- Issue 12.6 (Cross-Platform Testing Support) â€“ coordination point for GitHub-hosted macOS simulators.

## Estimated Effort
Medium â€“ touches shared helpers, multiple UI test files, and CI configuration.

## Success Metrics
- 0 flaky UI test failures across three consecutive GitHub Actions runs on `main`.
- Average hosted-run duration for each UI shard < 12 minutes.
- Failure logs include accessibility tree snippets for root-cause analysis.

## Testing Strategy
- Run updated UI shards locally with the new timeout scale set to 1.0 and in CI with â‰¥ 1.5, comparing runtimes.
- Validate that helper diagnostics print expected context by forcing a known failure in a sandbox branch.
- Ensure `TestResults/` captures per-shard logs and that the rotation policy retains the latest three artifacts.

## Related Issues
- Issue 12.5: Automated Accessibility Testing (shares helper infrastructure).
- Pending sub-issues may be spawned for individual suite refactors (e.g., `ContentDiscoveryUITests`).

## Notes
- Keep launch environment changes opt-in for local runs; developers can override via Xcode scheme arguments.
- Consider scripting a lightweight health check that confirms the environment flag is honored before running the full suite.
